{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNqjxujccV_d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmwAxFSpck4Y"
   },
   "source": [
    "### Key Components:\n",
    "\n",
    "- **entity_allowed_units**: Dictionary containing allowed units for each entity (width, depth, height, weight, voltage, etc.).\n",
    "- **unit_normalization_map**: Mapping of unit abbreviations and alternative forms to standard units.\n",
    "- **entity_keywords**: Dictionary of keywords used to identify specific entities (e.g., 'width', 'weight') in the extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgxNx8u_crp9"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='ocr_pipeline_part1.log',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "entity_allowed_units = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n",
    "                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "unit_normalization_map = {\n",
    "    'cm': 'centimetre', 'centimeter': 'centimetre', 'centimetres': 'centimetre', 'centimeters': 'centimetre',\n",
    "    'm': 'metre', 'meter': 'metre', 'metres': 'metre', 'meters': 'metre',\n",
    "    'mm': 'millimetre', 'millimeter': 'millimetre', 'millimetres': 'millimetre', 'millimeters': 'millimetre',\n",
    "    'ft': 'foot', 'feet': 'foot', 'foot': 'foot',\n",
    "    'in': 'inch', 'inch': 'inch', 'inches': 'inch',\n",
    "    'yd': 'yard', 'yard': 'yard', 'yards': 'yard',\n",
    "    'g': 'gram', 'gram': 'gram', 'grams': 'gram',\n",
    "    'kg': 'kilogram', 'kilogram': 'kilogram', 'kilograms': 'kilogram',\n",
    "    'mg': 'milligram', 'milligram': 'milligram', 'milligrams': 'milligram',\n",
    "    'μg': 'microgram', 'microgram': 'microgram', 'micrograms': 'microgram',\n",
    "    'lb': 'pound', 'lbs': 'pound', 'pound': 'pound', 'pounds': 'pound',\n",
    "    'oz': 'ounce', 'ounce': 'ounce', 'ounces': 'ounce',\n",
    "    'ton': 'ton', 'tons': 'ton',\n",
    "    'kv': 'kilovolt', 'kilovolt': 'kilovolt', 'kilovolts': 'kilovolt',\n",
    "    'mv': 'millivolt', 'millivolt': 'millivolt', 'millivolts': 'millivolt',\n",
    "    'v': 'volt', 'volt': 'volt', 'volts': 'volt',\n",
    "    'kw': 'kilowatt', 'kilowatt': 'kilowatt', 'kilowatts': 'kilowatt',\n",
    "    'w': 'watt', 'watt': 'watt', 'watts': 'watt',\n",
    "    'l': 'litre', 'liter': 'litre', 'litre': 'litre', 'liters': 'litre', 'litres': 'litre',\n",
    "    'ml': 'millilitre', 'millilitre': 'millilitre', 'milliliter': 'millilitre', 'milliliters': 'millilitre', 'millilitres': 'millilitre',\n",
    "    'cl': 'centilitre', 'centilitre': 'centilitre', 'centiliter': 'centilitre', 'centiliters': 'centilitre', 'centilitres': 'centilitre',\n",
    "    'dl': 'decilitre', 'decilitre': 'decilitre', 'deciliter': 'decilitre', 'deciliters': 'decilitre', 'decilitres': 'decilitre',\n",
    "    'μl': 'microlitre', 'microlitre': 'microlitre', 'microliter': 'microlitre', 'microliters': 'microlitre', 'microlitres': 'microlitre',\n",
    "    'gal': 'gallon', 'gallon': 'gallon', 'gallons': 'gallon',\n",
    "    'cup': 'cup', 'cups': 'cup',\n",
    "    'pt': 'pint', 'pint': 'pint', 'pints': 'pint',\n",
    "    'qt': 'quart', 'quart': 'quart', 'quarts': 'quart',\n",
    "    'fl oz': 'fluid ounce', 'fluid ounce': 'fluid ounce', 'fluid ounces': 'fluid ounce',\n",
    "    'cu ft': 'cubic foot', 'cubic foot': 'cubic foot', 'cubic feet': 'cubic foot',\n",
    "    'cu in': 'cubic inch', 'cubic inch': 'cubic inch', 'cubic inches': 'cubic inch',\n",
    "    'imperial gallon': 'imperial gallon', 'imperial gallons': 'imperial gallon',\n",
    "}\n",
    "\n",
    "allowed_units = set()\n",
    "for units in entity_allowed_units.values():\n",
    "    allowed_units.update(units)\n",
    "\n",
    "entity_keywords = {\n",
    "    'width': ['width', 'breadth', 'wide'],\n",
    "    'depth': ['depth'],\n",
    "    'height': ['height', 'length'],\n",
    "    'item_weight': ['weight', 'wt'],\n",
    "    'maximum_weight_recommendation': ['maximum weight', 'recommended weight', 'max weight', 'max wt', 'maximum wt'],\n",
    "    'voltage': ['voltage', 'volt'],\n",
    "    'wattage': ['wattage', 'watt'],\n",
    "    'item_volume': ['capacity', 'volume', 'size']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMZcOcBics9y"
   },
   "source": [
    "### Functions:\n",
    "\n",
    "- `normalize_unit(unit)`:\n",
    "  Normalize units to a standard form if they exist in the normalization map.\n",
    "  \n",
    "- `preprocess_image(img, max_size=1024)`:\n",
    "  Resize the image to a maximum size for OCR processing.\n",
    "  \n",
    "- `extract_numerical_values(text, entity)`:\n",
    "  Extract numerical values and associated units from the text, based on the provided entity (e.g., 'width', 'weight').\n",
    "  \n",
    "- `extract_dimensions_pattern(text)`:\n",
    "  Extract length, width, and height dimensions from the text using a specific pattern (e.g., \"12 x 24 x 36 cm\").\n",
    "  \n",
    "- `extract_entity_values(text, query_entities)`:\n",
    "  Extract values for multiple entities (e.g., weight, volume) from the provided text by looking for keywords and associated numerical values.\n",
    "  \n",
    "- `extract_and_save_entities(df, img_dir, output_csv='ocr_results.csv')`:\n",
    "  The main function that processes a dataframe containing image paths, applies OCR, extracts relevant entities and their values, and saves the results in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufHOoiQMXW1W"
   },
   "outputs": [],
   "source": [
    "def normalize_unit(unit):\n",
    "    unit = unit.lower().strip()\n",
    "    normalized_unit = unit_normalization_map.get(unit, unit)\n",
    "    if normalized_unit in allowed_units:\n",
    "        return normalized_unit\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def preprocess_image(img, max_size=1024):\n",
    "    height, width = img.shape[:2]\n",
    "    if max(height, width) > max_size:\n",
    "        scaling_factor = max_size / float(max(height, width))\n",
    "        img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def extract_numerical_values(text, entity):\n",
    "    units = entity_allowed_units.get(entity, set())\n",
    "    if not units:\n",
    "        return []\n",
    "\n",
    "    all_units = units.copy()\n",
    "    for unit in units:\n",
    "        for abbr, full_unit in unit_normalization_map.items():\n",
    "            if full_unit == unit:\n",
    "                all_units.add(abbr)\n",
    "\n",
    "    units_escaped = [re.escape(u) for u in all_units]\n",
    "    pattern = r'(\\d+(?:.\\d+)?)\\s*(' + '|'.join(units_escaped) + r')\\b'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    results = []\n",
    "    for match in matches:\n",
    "        number_str = match[0]\n",
    "        unit = match[1]\n",
    "        normalized_unit = normalize_unit(unit)\n",
    "        if normalized_unit:\n",
    "            try:\n",
    "                number = float(number_str)\n",
    "                results.append((number, normalized_unit))\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return results\n",
    "\n",
    "def extract_dimensions_pattern(text):\n",
    "    pattern = r'(\\d+(?:.\\d+)?)\\sx\\s(\\d+(?:.\\d+)?)\\sx\\s(\\d+(?:.\\d+)?)\\s*([a-zA-Z]+)'\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    results = {}\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            length_value = float(match[0])\n",
    "            width_value = float(match[1])\n",
    "            height_value = float(match[2])\n",
    "            unit = match[3]\n",
    "            normalized_unit = normalize_unit(unit)\n",
    "            if normalized_unit:\n",
    "                results['length'] = (length_value, normalized_unit)\n",
    "                results['width'] = (width_value, normalized_unit)\n",
    "                results['height'] = (height_value, normalized_unit)\n",
    "                break\n",
    "    return results\n",
    "\n",
    "def extract_entity_values(text, query_entities):\n",
    "    entity_matches = {entity: [] for entity in query_entities}\n",
    "\n",
    "    dimension_matches = extract_dimensions_pattern(text)\n",
    "    if dimension_matches:\n",
    "        for entity in query_entities:\n",
    "            if entity in dimension_matches:\n",
    "                entity_matches[entity].append(dimension_matches[entity])\n",
    "\n",
    "    for entity in query_entities:\n",
    "        if not entity_matches[entity]:\n",
    "            keywords = entity_keywords.get(entity, [])\n",
    "            for keyword in keywords:\n",
    "                pattern = r'\\b' + re.escape(keyword) + r'\\b.{0,20}?(\\d+(?:.\\d+)?)(?:\\s*([a-zA-Z]+))?'\n",
    "                matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "                if matches:\n",
    "                    for match in matches:\n",
    "                        number_str = match[0]\n",
    "                        unit = match[1] if len(match) > 1 else None\n",
    "                        if unit:\n",
    "                            normalized_unit = normalize_unit(unit)\n",
    "                        else:\n",
    "                            normalized_unit = None\n",
    "\n",
    "                        try:\n",
    "                            number = float(number_str)\n",
    "                            if normalized_unit:\n",
    "                                entity_matches[entity].append((number, normalized_unit))\n",
    "                            else:\n",
    "                                entity_matches[entity].append((number, None))\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "\n",
    "        if not entity_matches[entity]:\n",
    "            entity_matches.pop(entity)\n",
    "\n",
    "    return entity_matches\n",
    "\n",
    "def ocr_extract_entities(img_path, query_entities):\n",
    "    \"\"\"\n",
    "    Perform OCR on the image data and extract specified entities.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            logging.warning(f\"Could not read image {img_path}\")\n",
    "            return {entity: [] for entity in query_entities}\n",
    "\n",
    "        img = preprocess_image(img)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        result = reader.readtext(img, detail=0, paragraph=True)\n",
    "        text = ' '.join(result)\n",
    "\n",
    "        extracted_entities = extract_entity_values(text, query_entities)\n",
    "        return extracted_entities\n",
    "    except Exception as e:\n",
    "        logging.error(f\"OCR extraction failed for {img_path}: {e}\")\n",
    "        return {entity: [] for entity in query_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-mBA362idoRC"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    test_csv_path = '/kaggle/input/testfile2/test.csv'\n",
    "    images_folder = '/kaggle/input/the-dataset/images/test'\n",
    "    output_file = 'output.csv'\n",
    "    df = pd.read_csv(test_csv_path)\n",
    "    logging.info(f\"Loaded {len(df)} entries from test.csv\")\n",
    "\n",
    "    df_part = df.reset_index(drop=True)\n",
    "    logging.info(f\"Processing all {len(df_part)} rows\")\n",
    "\n",
    "    ocr_cache = {}\n",
    "    output_list = []\n",
    "    total = len(df_part)\n",
    "\n",
    "    for idx, row in tqdm(df_part.iterrows(), total=total):\n",
    "        index = row['index']\n",
    "        image_link = row['image_link']\n",
    "        entity_name = row['entity_name']\n",
    "        image_filename = os.path.basename(image_link)\n",
    "        image_path = os.path.join(images_folder, image_filename)\n",
    "\n",
    "        if image_filename in ocr_cache:\n",
    "            extracted_entities = ocr_cache[image_filename]\n",
    "        else:\n",
    "            extracted_entities = ocr_extract_entities(image_path, [entity_name])\n",
    "            ocr_cache[image_filename] = extracted_entities\n",
    "\n",
    "        entity_values = extracted_entities.get(entity_name, [])\n",
    "\n",
    "        if entity_values:\n",
    "            prediction = ''\n",
    "            for number, unit in entity_values:\n",
    "                if unit:\n",
    "                    if float(number).is_integer():\n",
    "                        number_formatted = f\"{int(number)}\"\n",
    "                    else:\n",
    "                        number_formatted = f\"{number:.2f}\".rstrip('0').rstrip('.')\n",
    "                    prediction = f\"{number_formatted} {unit}\"\n",
    "                    break\n",
    "        else:\n",
    "            prediction = \"\"\n",
    "\n",
    "        output_list.append({'index': index, 'prediction': prediction})\n",
    "\n",
    "    output_df = pd.DataFrame(output_list)\n",
    "    output_df = output_df.set_index('index')\n",
    "    output_df = output_df.reindex(df['index'])\n",
    "    output_df = output_df.reset_index()\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    logging.info(f\"Processing completed. Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
